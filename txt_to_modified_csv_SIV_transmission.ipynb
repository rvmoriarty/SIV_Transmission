{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the .txt file to ordered .csv \n",
    "\n",
    "Now that we have our individual .txt files from epitope_analysis.ipynb, we will translate each sequence and count the times each amino acid sequence appears. The files will have additional data added, including the days post infection, the animal ID, the epitope name, replicate, and the frequency of each observed amino acid sequence in that sample. This .csv file can then be further analyzed using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import Bio.Seq\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Enter the working directory where your .txt files are located\"\"\"\n",
    "\n",
    "WD = \"~/Epitope_analysis/outputs\"\n",
    "\n",
    "# make sure you are in the right location, use '-' instead of '_' between animal, dpi, and epitope \n",
    "\n",
    "os.chdir(WD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define required functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_files(files):\n",
    "    \"\"\" Take the list of files that were generated through a looped version of something Dave made, then \n",
    "        make a list of files that have sufficient (arbitrary) amount of reads, mark those that have epitopes\n",
    "        but don't make thresholds, and those that are completely empty\n",
    "        \n",
    "        Args: \n",
    "            files = list of .txt files output \n",
    "        Returns:\n",
    "            four items: one list of the files that had sufficient njumber of epitopes, one that has files with\n",
    "                low number of sequences, one of empties, and then one that lists how many sequences are in each\n",
    "                and every file so we can plot it.\n",
    "    \"\"\"\n",
    "    \n",
    "    contains_seqs = []\n",
    "    empties = []\n",
    "    low_seqs = []\n",
    "    num_seqs = []\n",
    "    for f in range(len(files)):\n",
    "        df = pd.read_csv(files[f], sep = '\\t')\n",
    "        num_seqs.append(int(pd.DataFrame.sum(df['barcode_count'])))\n",
    "        if len(df) > 0:\n",
    "            if pd.DataFrame.sum(df['barcode_count']) > 1000:\n",
    "                contains_seqs.append(files[f])\n",
    "            else:\n",
    "                low_seqs.append(files[f])\n",
    "        else:\n",
    "            empties.append(files[f])\n",
    "    print(\"There are \" + str(len(contains_seqs)) + \" files with 1000+ epitope sequences detected, \\n\" + \n",
    "          str(len(low_seqs)) + \" with <1000 epitope sequences detected, \\nand \" + \n",
    "          str(len(empties)) + \" empty files.\")\n",
    "    return contains_seqs, low_seqs, empties, num_seqs\n",
    "\n",
    "def identify_animals(files):\n",
    "    \"\"\"Let's figure out which animals have sequences with epitopes so we can later make a list of them\n",
    "        \n",
    "       Args:\n",
    "           files = list of .txt files from your data set \n",
    "       \n",
    "       Returns:\n",
    "           list of animals that have been sequenced\n",
    "    \"\"\"\n",
    "    \n",
    "    animals = set()\n",
    "    for f in files:\n",
    "        f = f.replace('_', '-')\n",
    "        a = f[0:f.index('-')]\n",
    "        animals.add(a)\n",
    "    return list(animals)\n",
    "\n",
    "def translate_and_group(file):\n",
    "    \"\"\"Since we care more about the effet on the translated product, translate the sequences and then combine \n",
    "       identical amino acid sequences.\n",
    "       \n",
    "       Args: \n",
    "           file = the file you want translated, in .txt form\n",
    "        \n",
    "       Returns:\n",
    "           pandas data frame with translated sequences and corresponding counts\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file, sep = '\\t')\n",
    "    aas = []\n",
    "    for seq in df['barcode_sequence']:\n",
    "        transl = Bio.Seq.translate(seq)\n",
    "        aas.append(transl)\n",
    "\n",
    "    df['barcode_sequence'] = pd.DataFrame(aas)\n",
    "    \n",
    "    return df.groupby(['barcode_sequence']).sum() \n",
    "\n",
    "def sort_by_animal(transl_files, animal_list):\n",
    "    \"\"\"Make lists of all files from each animal and return one list of sorted lists. \n",
    "       Args:\n",
    "           transl_files = made from translate_and_group, list of translated sequences and the counts\n",
    "           animal_list = made from identify_animals, sets up the unique animals in the data set \n",
    "       Returns:\n",
    "           sorted list of lists for each unique animal \n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_list = []\n",
    "    for a in animal_list:\n",
    "        byanimal = []\n",
    "        for t in transl_files:\n",
    "            if t[0][0:len(a)] == a:\n",
    "                byanimal.append(t)\n",
    "        sorted_list.append(byanimal)\n",
    "    return sorted_list\n",
    "\n",
    "def identify_epitope(sorted_list_name):\n",
    "    \"\"\"Take a file from the sorted list and label which epitopes are found\n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want epitopes from \n",
    "        \n",
    "        Returns:\n",
    "            the names of the epitopes found \"\"\"\n",
    "    if \"GW9\" in sorted_list_name[0]:\n",
    "        epitope_name = \"GW9\"\n",
    "    elif \"RM9\" in sorted_list_name[0]:\n",
    "        epitope_name = \"RM9\"\n",
    "    #epitope_name = sorted_list_name[0][sorted_list_name[0].index('ep')+4:sorted_list_name[0].index('.')]\n",
    "    return epitope_name\n",
    "\n",
    "def identify_dpi(sorted_list_name):\n",
    "    \"\"\"Take a file from the sorted list and label the time point\n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want dpi from \n",
    "        \n",
    "        Returns:\n",
    "            timepoint \"\"\"\n",
    "    name = sorted_list_name[0].replace('_', '-')\n",
    "    dpi = name[name.index('-')+4:name.index('.')]\n",
    "    \n",
    "    return dpi\n",
    "\n",
    "def identify_replicate(sorted_list_name):\n",
    "    \"\"\"Take a file from the sorted list and label the replicate\n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want replicate from \n",
    "        \n",
    "        Returns:\n",
    "            replicate \n",
    "    \"\"\"\n",
    "    rep = sorted_list_name[0][sorted_list_name[0].index('ep')-1:sorted_list_name[0].index('ep')+3]\n",
    "    return rep\n",
    "\n",
    "def identify_animal(sorted_list_name):\n",
    "    \"\"\"Take a file from the sorted list and label the animal \n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want replicate from \n",
    "        \n",
    "        Returns:\n",
    "            animal number\n",
    "    \"\"\"\n",
    "    if '-' in sorted_list_name[0]:\n",
    "        animal = sorted_list_name[0][:sorted_list_name[0].index('-')]\n",
    "    else:\n",
    "        animal = sorted_list_name[0][:sorted_list_name[0].index('_')]\n",
    "    return animal\n",
    "\n",
    "def write_translated_csv(sorted_file):\n",
    "    \"\"\"Take a file from the sorted list and write it as a .csv \n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want replicate from \n",
    "        \n",
    "        Returns:\n",
    "            csv of the translated file \n",
    "    \"\"\"\n",
    "    filename = str(identify_animal(sorted_file)) + \"_\" + str(identify_dpi(sorted_file)) + \"_\" + str(identify_epitope(sorted_file)) + \".csv\"\n",
    "    sorted_file[1].to_csv(filename)\n",
    "    \n",
    "def write_translated_csv_LOW(sorted_file):\n",
    "    \"\"\"Take a file from the sorted list of samples with <1000 counts and write it as a .csv \n",
    "    \n",
    "        Args:\n",
    "            sorted_list_name = file from the list, sorted by animal, that you want replicate from \n",
    "        \n",
    "        Returns:\n",
    "            csv of the translated file \n",
    "    \"\"\"\n",
    "    filename = str(identify_animal(sorted_file)) + \"_\" + str(identify_dpi(sorted_file)) + \"_\" + str(identify_epitope(sorted_file)) + \"_\" + str(identify_replicate(sorted_file)) + \"_LOW.csv\"\n",
    "    sorted_file[1].to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the .txt files, remove the empty files, and plot the distribution of number of identified sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfiles = [f for f in glob.glob(\"*_counts.txt\")]\n",
    "all_files = remove_empty_files(txtfiles)\n",
    "viable_files = all_files[0]\n",
    "\n",
    "plt.plot(sorted(all_files[3], reverse=True))\n",
    "plt.xlabel(\"Number of Files\")\n",
    "plt.ylabel(\"Number of Sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_files = []\n",
    "for v in viable_files:\n",
    "    translated_files.append((v, translate_and_group(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = identify_animals(txtfiles)\n",
    "sorted_list = sort_by_animal(translated_files, animals)\n",
    "\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sorted_list:\n",
    "    for t in s:\n",
    "        t[1]['animal'] = identify_animal(t)\n",
    "        t[1]['epitope'] = identify_epitope(t)\n",
    "        t[1]['dpi'] = identify_dpi(t)\n",
    "        #t[1]['rep'] = identify_replicate(t)\n",
    "        t[1]['freq'] = t[1]['barcode_count']/t[1]['barcode_count'].sum()\n",
    "        write_translated_csv(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section was put in here so I could still keep the files that had low sequence counts, but would know to take \n",
    "# the results with a little caution begcause low coverage may have skewed the results. \n",
    "\n",
    "low_seqs = []\n",
    "for s in all_files[1]:\n",
    "    low_seqs.append((s, translate_and_group(s)))\n",
    "    \n",
    "sorted_list_low = sort_by_animal(low_seqs, animals)\n",
    "\n",
    "for s in sorted_list_low:\n",
    "    for t in s:\n",
    "        t[1]['animal'] = identify_animal(t)\n",
    "        t[1]['epitope'] = identify_epitope(t)\n",
    "        t[1]['dpi'] = identify_dpi(t)\n",
    "        #t[1]['rep'] = identify_replicate(t)\n",
    "        write_translated_csv_LOW(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are filtering out any epitope sequence that comprises less than 1% of the total frequency. These will be \n",
    "# grouped into an \"other\" group. \n",
    "\n",
    "filtered_list = []\n",
    "merged_list = []\n",
    "for s in sorted_list:\n",
    "    filtered_animal = []\n",
    "    for t in s:\n",
    "        df = t[1].loc[t[1]['freq'] > 0.01]\n",
    "        filtered_name = t[0][0:t[0].index(\".\")] + \".filtered.csv\"\n",
    "        filtered_animal.append(df)\n",
    "        df.to_csv(filtered_name)\n",
    "    \n",
    "    filtered_list.append(filtered_animal)\n",
    "\n",
    "    merged_animal = pd.concat(filtered_animal)\n",
    "    merged_list.append(merged_animal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
